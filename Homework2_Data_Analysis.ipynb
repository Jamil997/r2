{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MATH 541 Data Analysis and Statistical Learning\n",
        "## Assignment 2 SVM\n",
        "## Course Instructor- Dr. Rustem Takhanov\n",
        "## Done by Jamil Zhumabek"
      ],
      "metadata": {
        "id": "D8dixBmMouCV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Our dataset contains data is about\n",
        " the localization sites of proteins within the cell of the bacterium E. coli.\n",
        "\n",
        "It is used to predict the sub-cellular localization of proteins.\n",
        "In our case, $y_i$ labels are divided into 2 categories: cytoplasm (cp) and not cp.\n",
        "\n",
        "https://archive.ics.uci.edu/dataset/39/ecoli"
      ],
      "metadata": {
        "id": "8CijPnI7g_uG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to have an access to UCI Machine Learning Repository:"
      ],
      "metadata": {
        "id": "ps_ZLXPSsMlx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-xRdB69I21O",
        "outputId": "1a181dee-3844-458e-abc2-0bd607779fd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.10/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.8.30)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading the dataset"
      ],
      "metadata": {
        "id": "WVGT235ro6Ly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "ecoli = fetch_ucirepo(id=39)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = ecoli.data.features\n",
        "y = ecoli.data.targets\n",
        "\n",
        "# metadata\n",
        "print(ecoli.metadata)\n",
        "\n",
        "# variable information\n",
        "print(ecoli.variables)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLnuOU86MICt",
        "outputId": "8efd0e35-9501-43b6-d242-03c9f3c24e35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'uci_id': 39, 'name': 'Ecoli', 'repository_url': 'https://archive.ics.uci.edu/dataset/39/ecoli', 'data_url': 'https://archive.ics.uci.edu/static/public/39/data.csv', 'abstract': 'This data contains protein localization sites', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 336, 'num_features': 7, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['class'], 'index_col': ['Sequence'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1996, 'last_updated': 'Thu Feb 15 2024', 'dataset_doi': '10.24432/C5388M', 'creators': ['Kenta Nakai'], 'intro_paper': {'ID': 391, 'type': 'NATIVE', 'title': 'A Probabilistic Classification System for Predicting the Cellular Localization Sites of Proteins', 'authors': 'P. Horton, K. Nakai', 'venue': 'Intelligent Systems in Molecular Biology', 'year': 1996, 'journal': None, 'DOI': None, 'URL': 'https://www.semanticscholar.org/paper/A-Probabilistic-Classification-System-for-the-Sites-Horton-Nakai/623c5e3441a1e08e3da2c68924c85e4b95274652', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'The references below describe a predecessor to this dataset and its development. They also give results (not cross-validated) for classification by a rule-based expert system with that version of the dataset.\\r\\n\\r\\nReference: \"Expert Sytem for Predicting Protein Localization Sites in Gram-Negative Bacteria\", Kenta Nakai & Minoru Kanehisa,  PROTEINS: Structure, Function, and Genetics 11:95-110, 1991.\\r\\n\\r\\nReference: \"A Knowledge Base for Predicting Protein Localization Sites in Eukaryotic Cells\", Kenta Nakai & Minoru Kanehisa, Genomics 14:897-911, 1992.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': \"  1.  Sequence Name: Accession number for the SWISS-PROT database\\r\\n  2.  mcg: McGeoch's method for signal sequence recognition.\\r\\n  3.  gvh: von Heijne's method for signal sequence recognition.\\r\\n  4.  lip: von Heijne's Signal Peptidase II consensus sequence score. Binary attribute.\\r\\n  5.  chg: Presence of charge on N-terminus of predicted lipoproteins. Binary attribute.\\r\\n  6.  aac: score of discriminant analysis of the amino acid content of outer membrane and periplasmic proteins.\\r\\n  7. alm1: score of the ALOM membrane spanning region prediction program.\\r\\n  8. alm2: score of ALOM program after excluding putative cleavable signal regions from the sequence.\", 'citation': None}}\n",
            "       name     role         type demographic  \\\n",
            "0  Sequence       ID  Categorical        None   \n",
            "1       mcg  Feature   Continuous        None   \n",
            "2       gvh  Feature   Continuous        None   \n",
            "3       lip  Feature       Binary        None   \n",
            "4       chg  Feature       Binary        None   \n",
            "5       aac  Feature   Continuous        None   \n",
            "6      alm1  Feature   Continuous        None   \n",
            "7      alm2  Feature   Continuous        None   \n",
            "8     class   Target  Categorical        None   \n",
            "\n",
            "                                         description units missing_values  \n",
            "0       Accession number for the SWISS-PROT database  None             no  \n",
            "1   McGeoch's method for signal sequence recognition  None             no  \n",
            "2  von Heijne's method for signal sequence recogn...  None             no  \n",
            "3  von Heijne's Signal Peptidase II consensus seq...  None             no  \n",
            "4  Presence of charge on N-terminus of predicted ...  None             no  \n",
            "5  score of discriminant analysis of the amino ac...  None             no  \n",
            "6  score of the ALOM membrane spanning region pre...  None             no  \n",
            "7  score of ALOM program after excluding putative...  None             no  \n",
            "8                                               None  None             no  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert the target variable y into a binary format by labeling cp as 1 and all others as 0."
      ],
      "metadata": {
        "id": "EyQozOrJIlAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_binary = (y == 'cp').astype(int)\n"
      ],
      "metadata": {
        "id": "JyN1ndEJ-2a0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting the Data\n",
        "\n",
        "We split our dataset into 3 categories: Train( 70%), Validation( 15%) and Test(15 %).\n",
        "\n",
        " It's a standard ratio to separate the dataset in such a problems- so that we can be sure that out Training Set is large enough to generalize the pattern, and Validation and Test sets are in equal proprotion."
      ],
      "metadata": {
        "id": "0E9FdTV3IuBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Initial split: Train+Validation and Test\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    X, y_binary, test_size=0.15, stratify=y_binary, random_state=42\n",
        ")\n",
        "\n",
        "# Secondary split: Train and Validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=0.1765, stratify=y_train_val, random_state=42\n",
        ")  # 0.1765 * 0.85 ≈ 15%\n"
      ],
      "metadata": {
        "id": "_AUSe02CIxy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Standardize all your features $(X_1, \\ldots, X_p)$\n"
      ],
      "metadata": {
        "id": "aVHWfCINJgFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def standardize_features(X):\n",
        "    # Calculating means and variances\n",
        "    mean_X = X.mean(axis=0)\n",
        "    mean_X2 = (X**2).mean(axis=0)\n",
        "    variance_X = mean_X2 - mean_X**2\n",
        "\n",
        "    # Applying standardization formula\n",
        "    X_standardized = (X - mean_X) / np.sqrt(variance_X)\n",
        "    return X_standardized\n",
        "\n",
        "X_train_standardized = standardize_features(X_train)\n"
      ],
      "metadata": {
        "id": "S3yu_DdcJjk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7 step\n",
        "\n",
        "Our candidates for values of $C_i$ are $0.1, 1, 10, 100, 1000$.\n"
      ],
      "metadata": {
        "id": "_vs6XDPrwSBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Training data (X_train, y_train)\n",
        "C_values = [0.1, 1, 10, 100, 1000]\n",
        "weights = []\n",
        "\n",
        "for C in C_values:\n",
        "    # Train SVM with linear kernel\n",
        "    model = SVC(C=C, kernel='linear')\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Get the weight vector\n",
        "    w = model.coef_.flatten()  # Extract w\n",
        "    weights.append(w)\n",
        "\n",
        "    print(f\"C: {C}, Weight Vector: {w}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouqLV-ECLOxZ",
        "outputId": "e69ab421-e041-49f3-b4c6-0903cf0872a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C: 0.1, Weight Vector: [-1.42922963 -1.36307003 -0.26       -0.05       -0.456      -2.18953265\n",
            " -0.61769224]\n",
            "C: 1, Weight Vector: [-2.294289   -3.40381375 -0.29203717 -0.28080497 -1.22245494 -4.53271118\n",
            " -0.09967743]\n",
            "C: 10, Weight Vector: [-3.07560936e+00 -5.88035716e+00 -4.44089210e-15  7.10542736e-15\n",
            " -1.42376842e+00 -9.40134581e+00  1.46999885e+00]\n",
            "C: 100, Weight Vector: [ -3.40951884  -6.84156164   0.           0.          -0.45216094\n",
            " -14.86007449   4.71904433]\n",
            "C: 1000, Weight Vector: [-3.14724229e+00 -7.48079037e+00  4.54747351e-13  0.00000000e+00\n",
            " -6.47371865e-01 -1.99117525e+01  8.55692465e+00]\n"
          ]
        },
       
    {
      "cell_type": "markdown",
      "source": [
        "## 8 step"
      ],
      "metadata": {
        "id": "5ffcVeJNwGha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a) Calculating the Error Rate:"
      ],
      "metadata": {
        "id": "I73hJpWOtVSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Predict on training set\n",
        "y_train_pred = model.predict(X_train)\n",
        "\n",
        "# Error rate calculation\n",
        "error_rate = 100 * (1 - accuracy_score(y_train, y_train_pred))\n",
        "print(f\"Error Rate: {error_rate:.2f}%\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVKY0tERMRcZ",
        "outputId": "c025c178-5d59-4156-bb4a-3fdfe81ea6dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error Rate: 2.14%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b) Precision and Recall"
      ],
      "metadata": {
        "id": "IR9WniMUtZ6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "# Calculate precision and recall\n",
        "precision = precision_score(y_train, y_train_pred, pos_label=1)\n",
        "recall = recall_score(y_train, y_train_pred, pos_label=1)\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ru8lgo-hNt-P",
        "outputId": "33ee9e3f-47f3-4a3a-9382-7285f0645c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.99\n",
            "Recall: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (c) Number of Support Vectors"
      ],
      "metadata": {
        "id": "3Lea41I4Nx-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of support vectors\n",
        "num_support_vectors = len(model.support_vectors_)\n",
        "print(f\"Number of Support Vectors: {num_support_vectors}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3q2NYKheNyxv",
        "outputId": "b40d72d3-a7fc-4547-ed08-d12aec5bf134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Support Vectors: 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9 step\n",
        "Here we implement the same procedure, as in the step 8, but on the **Validation set**."
      ],
      "metadata": {
        "id": "ascazjXMUdnO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(a) Percent of Incorrectly Classified Examples (Error Rate):"
      ],
      "metadata": {
        "id": "kLazdYJCPYIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Predict on the validation set\n",
        "y_val_pred = model.predict(X_val)\n",
        "\n",
        "# Calculate error rate\n",
        "error_rate = 100 * (1 - accuracy_score(y_val, y_val_pred))\n",
        "print(f\"Error Rate for C = {C}: {error_rate:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd7oKdVgPahD",
        "outputId": "f255acba-ffa9-4f96-cd37-d819e51d2de9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error Rate for C = 1000: 1.96%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(b) Precision and Recall:"
      ],
      "metadata": {
        "id": "xMvD2TpoPgd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "# Calculate precision and recall\n",
        "precision = precision_score(y_val, y_val_pred, pos_label=1)\n",
        "recall = recall_score(y_val, y_val_pred, pos_label=1)\n",
        "\n",
        "print(f\"Precision for C = {C}: {precision:.2f}\")\n",
        "print(f\"Recall for C = {C}: {recall:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1rBCvOFPhcZ",
        "outputId": "ed416f7f-e469-4254-d09c-6d9895b9fc48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision for C = 1000: 1.00\n",
            "Recall for C = 1000: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(c) Calculate $F_{Β}$ Measure:"
      ],
      "metadata": {
        "id": "3OQOLs1kn2d8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "beta = 1  # Adjust based on problem needs\n",
        "f_beta = (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall)\n",
        "print(f\"F_{beta} Measure for C = {C}: {f_beta:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SBJRqKXPw8j",
        "outputId": "92990444-3c47-4c62-b408-e62ea804b569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F_1 Measure for C = 1000: 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### So, we have $F_1$ Measure 0.98 for C = 1000.\n",
        " $F_{0.5}$ and $F_2$ will be not computed.\n",
        "Since, in our dataset I assume that Precision and Recall are equally in prior.\n",
        "\n",
        " So, $F_1$ score is sufficient for our goals."
      ],
      "metadata": {
        "id": "nCFATDtwDiLb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Choosing Optimal C\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L-oohKkkP3dR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.values.ravel()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vd1kAYvRP44Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.squeeze()  # Converts DataFrame to Series (1D)\n"
      ],
      "metadata": {
        "id": "rUxvrv-yQTkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "beta = 1\n",
        "\n",
        "for C in C_values:\n",
        "    model = SVC(C=C, kernel='linear')\n",
        "    model.fit(X_train, y_train)\n",
        "    y_val_pred = model.predict(X_val)\n",
        "\n",
        "    # Metrics\n",
        "    error_rate = 100 * (1 - accuracy_score(y_val, y_val_pred))\n",
        "    precision = precision_score(y_val, y_val_pred, pos_label=1, zero_division=0)\n",
        "    recall = recall_score(y_val, y_val_pred, pos_label=1, zero_division=0)\n",
        "\n",
        "    # F_beta measure\n",
        "    if precision == 0 and recall == 0:\n",
        "        f_beta = 0\n",
        "    else:\n",
        "        f_beta = (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall)\n",
        "\n",
        "    results.append([C, error_rate, precision, recall, f_beta])\n",
        "\n",
        "# Convert to DataFrame\n",
        "results_df = pd.DataFrame(results, columns=[\"C\", \"Error Rate (%)\", \"Precision\", \"Recall\", f\"F_{beta} Measure\"])\n",
        "print(results_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4LRQ1OXQXAp",
        "outputId": "e00446d4-9efb-4ef5-d257-8c2641d50850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        C  Error Rate (%)  Precision    Recall  F_1 Measure\n",
            "0     0.1        3.921569        1.0  0.909091     0.952381\n",
            "1     1.0        1.960784        1.0  0.954545     0.976744\n",
            "2    10.0        3.921569        1.0  0.909091     0.952381\n",
            "3   100.0        3.921569        1.0  0.909091     0.952381\n",
            "4  1000.0        1.960784        1.0  0.954545     0.976744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apparently, the best value for C here is $C=1$ and $C=1000$, with identical values for all characteristics."
      ],
      "metadata": {
        "id": "36u-9gKXuet5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10\n",
        "Choose 3–5 candidates for $C : C'_1, C'_2, \\dots, C'_5$ and find weight vectors (using only the training set) for Model $\\alpha$, where $\\alpha = \\text{II–IV}$.\n",
        "\n",
        "Note, that we use $b=c=γ=1$ in all cases, and set m=3 for a model  II.\n"
      ],
      "metadata": {
        "id": "3kmGy7TbEXjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(a) Model II: Polynomial Kernel\n",
        "Using $b=1, c=1,$ and a degree $m=3$:"
      ],
      "metadata": {
        "id": "DiVSurWOS_ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "C_values = [0.01, 0.1, 1, 10, 100]\n",
        "degree = 3\n",
        "weights_poly = []\n",
        "\n",
        "for C in C_values:\n",
        "    model = SVC(C=C, kernel='poly', degree=degree, coef0=1, gamma=1)  # b=1, c=1\n",
        "    model.fit(X_train, y_train)\n",
        "    weights_poly.append(model.dual_coef_)  # We store support vector weights\n",
        "\n",
        "print(\"Polynomial Kernel Weights:\", weights_poly)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BubXu_qjTADR",
        "outputId": "88b448b8-9c75-4a03-b167-5389d941a1ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polynomial Kernel Weights: [array([[-0.01      , -0.01      , -0.01      , -0.01      , -0.01      ,\n",
            "        -0.01      , -0.01      , -0.01      , -0.01      , -0.01      ,\n",
            "        -0.01      , -0.01      , -0.01      , -0.01      , -0.01      ,\n",
            "        -0.01      , -0.01      , -0.01      , -0.01      , -0.01      ,\n",
            "        -0.01      , -0.01      , -0.01      , -0.01      , -0.01      ,\n",
            "        -0.01      , -0.01      , -0.01      , -0.01      , -0.01      ,\n",
            "        -0.01      , -0.01      , -0.01      , -0.01      , -0.01      ,\n",
            "        -0.01      , -0.01      , -0.01      , -0.00627544, -0.01      ,\n",
            "        -0.01      , -0.01      , -0.01      , -0.01      , -0.01      ,\n",
            "        -0.01      , -0.01      , -0.01      , -0.01      , -0.00858618,\n",
            "        -0.01      , -0.01      , -0.01      , -0.01      ,  0.01      ,\n",
            "         0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
            "         0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
            "         0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
            "         0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
            "         0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
            "         0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
            "         0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
            "         0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
            "         0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
            "         0.01      ,  0.01      ,  0.00486162,  0.01      ,  0.01      ,\n",
            "         0.01      ,  0.01      ,  0.01      ]]), array([[-0.1       , -0.1       , -0.1       , -0.07967374, -0.1       ,\n",
            "        -0.1       , -0.1       , -0.1       , -0.1       , -0.1       ,\n",
            "        -0.1       , -0.07873767, -0.1       , -0.1       , -0.1       ,\n",
            "        -0.00105523, -0.1       , -0.1       , -0.1       , -0.1       ,\n",
            "        -0.1       , -0.1       , -0.1       , -0.1       ,  0.1       ,\n",
            "         0.1       ,  0.1       ,  0.1       ,  0.1       ,  0.1       ,\n",
            "         0.1       ,  0.1       ,  0.1       ,  0.1       ,  0.1       ,\n",
            "         0.1       ,  0.1       ,  0.1       ,  0.1       ,  0.1       ,\n",
            "         0.1       ,  0.05946663,  0.1       ,  0.1       ,  0.1       ,\n",
            "         0.1       ,  0.1       ]]), array([[-1.        , -0.79345084, -1.        , -1.        , -1.        ,\n",
            "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
            "        -0.71629567, -0.07805712,  1.        ,  0.02576751,  1.        ,\n",
            "         0.87263029,  1.        ,  1.        ,  0.68940582,  1.        ,\n",
            "         1.        ,  1.        ,  1.        ,  1.        ]]), array([[-10.        ,  -2.90364233, -10.        ,  -4.6835732 ,\n",
            "        -10.        ,  -5.81626823,  -6.98808493, -10.        ,\n",
            "         -3.92875392,  -0.13567685,  10.        ,   4.51251226,\n",
            "         10.        ,   7.14801474,   0.89566577,  10.        ,\n",
            "         10.        ,  10.        ,   1.89980669]]), array([[-1.00000000e+02, -5.75614912e-03, -2.18769281e+01,\n",
            "        -3.83097778e+01, -8.16573804e+00, -2.31253598e+01,\n",
            "        -7.31541870e-02, -1.00000000e+02, -7.80749539e+01,\n",
            "        -9.64467759e+01, -1.18253404e+01,  1.00000000e+02,\n",
            "         1.91796978e+01,  1.69798065e+01,  6.78498500e+01,\n",
            "         3.11040904e+01,  4.27903396e+01,  1.00000000e+02,\n",
            "         1.00000000e+02]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (b) Model III: Radial Basis Function (RBF) Kernel\n",
        "Using $γ =1$ :\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "29jcR7lhT75_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights_rbf = []\n",
        "\n",
        "for C in C_values:\n",
        "    model = SVC(C=C, kernel='rbf', gamma=1)  # gamma=1\n",
        "    model.fit(X_train, y_train)\n",
        "    weights_rbf.append(model.dual_coef_)  # Store support vector weights\n",
        "\n",
        "print(\"RBF Kernel Weights:\", weights_rbf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRX-L80aUL5W",
        "outputId": "d2b347a4-fa16-4ed7-db76-d897ee069eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RBF Kernel Weights: [array([[-0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01,\n",
            "        -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01,\n",
            "        -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01,\n",
            "        -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01,\n",
            "        -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01,\n",
            "        -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01,\n",
            "        -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01,\n",
            "        -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01,\n",
            "        -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01,\n",
            "        -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01,\n",
            "        -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01,\n",
            "         0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,\n",
            "         0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,\n",
            "         0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,\n",
            "         0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,\n",
            "         0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,\n",
            "         0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,\n",
            "         0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,\n",
            "         0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,\n",
            "         0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,\n",
            "         0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,\n",
            "         0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01]]), array([[-0.1       , -0.1       , -0.1       , -0.1       , -0.1       ,\n",
            "        -0.1       , -0.1       , -0.1       , -0.1       , -0.1       ,\n",
            "        -0.1       , -0.1       , -0.1       , -0.1       , -0.1       ,\n",
            "        -0.1       , -0.1       , -0.1       , -0.1       , -0.1       ,\n",
            "        -0.1       , -0.02119015, -0.1       , -0.1       , -0.1       ,\n",
            "        -0.1       , -0.1       , -0.1       , -0.1       , -0.1       ,\n",
            "        -0.1       , -0.1       , -0.1       , -0.1       , -0.1       ,\n",
            "        -0.1       , -0.1       , -0.1       , -0.1       , -0.1       ,\n",
            "        -0.1       , -0.1       , -0.1       , -0.1       , -0.1       ,\n",
            "        -0.1       , -0.1       , -0.1       , -0.1       , -0.1       ,\n",
            "        -0.1       , -0.1       , -0.1       , -0.1       , -0.1       ,\n",
            "        -0.1       , -0.1       , -0.1       , -0.1       , -0.1       ,\n",
            "        -0.1       , -0.1       , -0.1       , -0.1       , -0.1       ,\n",
            "        -0.1       , -0.1       , -0.1       , -0.1       , -0.1       ,\n",
            "        -0.1       , -0.1       , -0.1       ,  0.1       ,  0.1       ,\n",
            "         0.1       ,  0.1       ,  0.1       ,  0.1       ,  0.1       ,\n",
            "         0.1       ,  0.1       ,  0.1       ,  0.1       ,  0.1       ,\n",
            "         0.1       ,  0.1       ,  0.1       ,  0.1       ,  0.1       ,\n",
            "         0.1       ,  0.1       ,  0.1       ,  0.1       ,  0.1       ,\n",
            "         0.1       ,  0.1       ,  0.1       ,  0.1       ,  0.1       ,\n",
            "         0.1       ,  0.1       ,  0.1       ,  0.1       ,  0.1       ,\n",
            "         0.1       ,  0.1       ,  0.1       ,  0.1       ,  0.1       ,\n",
            "         0.1       ,  0.1       ,  0.1       ,  0.1       ,  0.1       ,\n",
            "         0.1       ,  0.1       ,  0.1       ,  0.1       ,  0.1       ,\n",
            "         0.1       ,  0.1       ,  0.1       ,  0.1       ,  0.1       ,\n",
            "         0.1       ,  0.1       ,  0.1       ,  0.1       ,  0.1       ,\n",
            "         0.1       ,  0.1       ,  0.1       ,  0.1       ,  0.1       ,\n",
            "         0.1       ,  0.1       ,  0.1       ,  0.1       ,  0.1       ,\n",
            "         0.02119015,  0.1       ,  0.1       ,  0.1       ,  0.1       ,\n",
            "         0.1       ]]), array([[-1.        , -0.2323986 , -1.        , -1.        , -1.        ,\n",
            "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
            "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
            "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
            "        -1.        , -0.5280699 , -1.        , -1.        , -1.        ,\n",
            "        -1.        , -1.        , -1.        , -0.63930542,  1.        ,\n",
            "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
            "         1.        ,  0.9454138 ,  1.        ,  1.        ,  1.        ,\n",
            "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
            "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
            "         1.        ,  1.        ,  1.        ,  1.        ,  0.45436012,\n",
            "         1.        ,  1.        ]]), array([[-10.        ,  -3.18142198, -10.        ,  -4.35790741,\n",
            "        -10.        , -10.        ,  -2.04394893,  -5.50473712,\n",
            "        -10.        , -10.        , -10.        , -10.        ,\n",
            "        -10.        ,  10.        ,  10.        ,  10.        ,\n",
            "          4.72332929,  10.        ,  10.        ,  10.        ,\n",
            "          0.36468614,  10.        ,  10.        ,  10.        ,\n",
            "         10.        ]]), array([[-100.        ,  -91.3093736 ,  -10.59789226,  -29.35227423,\n",
            "        -100.        ,  -41.5496203 ,  -96.14241852, -100.        ,\n",
            "         100.        ,   35.59241552,   45.25978675,   20.61622678,\n",
            "         100.        ,   24.73975128,    4.33717663,   38.40622194,\n",
            "         100.        ,  100.        ]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(c) Model IV: Sigmoid Kernel\n",
        "Using $b=1$, $c=1$, and $γ=1$:"
      ],
      "metadata": {
        "id": "peolrFjyURcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights_sigmoid = []\n",
        "\n",
        "for C in C_values:\n",
        "    model = SVC(C=C, kernel='sigmoid', coef0=1, gamma=1)  # gamma=1, b=1, c=1\n",
        "    model.fit(X_train, y_train)\n",
        "    weights_sigmoid.append(model.dual_coef_)  # Store support vector weights\n",
        "\n",
        "print(\"Sigmoid Kernel Weights:\", weights_sigmoid)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeO8OZRSUd_Y",
        "outputId": "f09356af-65ae-485b-8fa8-1f71e632e24a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sigmoid Kernel Weights: [array([[-0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01,\n",
            "        -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01,\n",
            "        -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01,\n",
            "        -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01,\n",
            "        -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01,\n",
            "        -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01,\n",
            "        -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01,\n",
            "        -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01,\n",
            "        -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01,\n",
            "        -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01,\n",
            "        -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01,\n",
            "         0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,\n",
            "         0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,\n",
            "         0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,\n",
            "         0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,\n",
            "         0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,\n",
            "         0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,\n",
            "         0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,\n",
            "         0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,\n",
            "         0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,\n",
            "         0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,\n",
            "         0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01]]), array([[-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1,\n",
            "        -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1,\n",
            "        -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1,\n",
            "        -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1,\n",
            "        -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1,\n",
            "        -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1,\n",
            "        -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1,\n",
            "        -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1,\n",
            "        -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1,\n",
            "         0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,\n",
            "         0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,\n",
            "         0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,\n",
            "         0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,\n",
            "         0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,\n",
            "         0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,\n",
            "         0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,\n",
            "         0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,\n",
            "         0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1]]), array([[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
            "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
            "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
            "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
            "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
            "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
            "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
            "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
            "         1.,  1.,  1.]]), array([[-10., -10., -10., -10., -10., -10., -10., -10., -10., -10., -10.,\n",
            "        -10., -10., -10., -10., -10., -10., -10., -10., -10., -10., -10.,\n",
            "        -10., -10., -10., -10., -10., -10., -10., -10., -10., -10., -10.,\n",
            "        -10., -10., -10., -10., -10., -10., -10., -10., -10., -10., -10.,\n",
            "        -10., -10., -10., -10., -10., -10., -10., -10., -10., -10., -10.,\n",
            "        -10., -10., -10., -10., -10., -10., -10., -10., -10., -10., -10.,\n",
            "        -10., -10., -10., -10., -10., -10., -10., -10., -10., -10., -10.,\n",
            "        -10., -10., -10., -10., -10., -10., -10., -10., -10., -10., -10.,\n",
            "        -10., -10., -10., -10., -10., -10., -10., -10., -10., -10., -10.,\n",
            "         10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
            "         10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
            "         10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
            "         10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
            "         10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
            "         10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
            "         10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
            "         10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,\n",
            "         10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.]]), array([[-100., -100., -100., -100., -100., -100., -100., -100., -100.,\n",
            "        -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n",
            "        -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n",
            "        -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n",
            "        -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n",
            "        -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n",
            "        -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n",
            "        -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n",
            "        -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n",
            "        -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n",
            "        -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n",
            "         100.,  100.,  100.,  100.,  100.,  100.,  100.,  100.,  100.,\n",
            "         100.,  100.,  100.,  100.,  100.,  100.,  100.,  100.,  100.,\n",
            "         100.,  100.,  100.,  100.,  100.,  100.,  100.,  100.,  100.,\n",
            "         100.,  100.,  100.,  100.,  100.,  100.,  100.,  100.,  100.,\n",
            "         100.,  100.,  100.,  100.,  100.,  100.,  100.,  100.,  100.,\n",
            "         100.,  100.,  100.,  100.,  100.,  100.,  100.,  100.,  100.,\n",
            "         100.,  100.,  100.,  100.,  100.,  100.,  100.,  100.,  100.,\n",
            "         100.,  100.,  100.,  100.,  100.,  100.,  100.,  100.,  100.,\n",
            "         100.,  100.,  100.,  100.,  100.,  100.,  100.,  100.,  100.,\n",
            "         100.,  100.,  100.,  100.,  100.,  100.,  100.,  100.,  100.,\n",
            "         100.,  100.,  100.,  100.,  100.,  100.,  100.,  100.,  100.]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11\n",
        " #### (b) Make estimations as at steps 8–9. Using those estimations, choose the best value $C = C^*_\\alpha$.\n",
        "\n",
        "Collect all your findings into a table.\n",
        "\n",
        "Here will run code snippets for different kernels separately, then combine the results in one table."
      ],
      "metadata": {
        "id": "IPgZ64gjU29y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C_values = [0.1, 1, 10, 100, 1000]  # Candidate C' values\n",
        "beta = 1  # For F1 score\n"
      ],
      "metadata": {
        "id": "mk4Z-QbHVFxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "results_poly = []\n",
        "\n",
        "for C in C_values:\n",
        "    model = SVC(C=C, kernel='poly', degree=3, coef0=1, gamma=1)  # Polynomial kernel\n",
        "    model.fit(X_train, y_train)\n",
        "    y_val_pred = model.predict(X_val)\n",
        "\n",
        "    # Calculate metrics\n",
        "    error_rate = 100 * (1 - accuracy_score(y_val, y_val_pred))\n",
        "    precision = precision_score(y_val, y_val_pred, pos_label=1, zero_division=0)\n",
        "    recall = recall_score(y_val, y_val_pred, pos_label=1, zero_division=0)\n",
        "    if precision == 0 and recall == 0:\n",
        "        f_beta = 0\n",
        "    else:\n",
        "        f_beta = (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall)\n",
        "\n",
        "    results_poly.append([C, error_rate, precision, recall, f_beta])\n",
        "\n",
        "# Convert to DataFrame\n",
        "import pandas as pd\n",
        "results_poly_df = pd.DataFrame(results_poly, columns=[\"C\", \"Error Rate (%)\", \"Precision\", \"Recall\", f\"F_{beta} Measure\"])\n",
        "print(\"Polynomial Kernel Results\")\n",
        "print(results_poly_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPnWAshnVUcr",
        "outputId": "3b482d77-f1f2-43ec-92fe-f4e5ea824f0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polynomial Kernel Results\n",
            "        C  Error Rate (%)  Precision    Recall  F_1 Measure\n",
            "0     0.1        1.960784   1.000000  0.954545     0.976744\n",
            "1     1.0        1.960784   1.000000  0.954545     0.976744\n",
            "2    10.0        1.960784   1.000000  0.954545     0.976744\n",
            "3   100.0        3.921569   0.954545  0.954545     0.954545\n",
            "4  1000.0        7.843137   0.875000  0.954545     0.913043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_rbf = []\n",
        "\n",
        "for C in C_values:\n",
        "    model = SVC(C=C, kernel='rbf', gamma=1)  # RBF kernel\n",
        "    model.fit(X_train, y_train)\n",
        "    y_val_pred = model.predict(X_val)\n",
        "\n",
        "    # Calculate metrics\n",
        "    error_rate = 100 * (1 - accuracy_score(y_val, y_val_pred))\n",
        "    precision = precision_score(y_val, y_val_pred, pos_label=1, zero_division=0)\n",
        "    recall = recall_score(y_val, y_val_pred, pos_label=1, zero_division=0)\n",
        "    if precision == 0 and recall == 0:\n",
        "        f_beta = 0\n",
        "    else:\n",
        "        f_beta = (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall)\n",
        "\n",
        "    results_rbf.append([C, error_rate, precision, recall, f_beta])\n",
        "\n",
        "results_rbf_df = pd.DataFrame(results_rbf, columns=[\"C\", \"Error Rate (%)\", \"Precision\", \"Recall\", f\"F_{beta} Measure\"])\n",
        "print(\"RBF Kernel Results\")\n",
        "print(results_rbf_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miSnzuflVavw",
        "outputId": "3d4fde9d-af4b-4635-d3e0-c20be01c4478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RBF Kernel Results\n",
            "        C  Error Rate (%)  Precision    Recall  F_1 Measure\n",
            "0     0.1        3.921569   1.000000  0.909091     0.952381\n",
            "1     1.0        1.960784   1.000000  0.954545     0.976744\n",
            "2    10.0        1.960784   1.000000  0.954545     0.976744\n",
            "3   100.0        3.921569   0.954545  0.954545     0.954545\n",
            "4  1000.0        3.921569   0.954545  0.954545     0.954545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_sigmoid = []\n",
        "\n",
        "for C in C_values:\n",
        "    model = SVC(C=C, kernel='sigmoid', coef0=1, gamma=1)  # Sigmoid kernel\n",
        "    model.fit(X_train, y_train)\n",
        "    y_val_pred = model.predict(X_val)\n",
        "\n",
        "    # Calculate metrics\n",
        "    error_rate = 100 * (1 - accuracy_score(y_val, y_val_pred))\n",
        "    precision = precision_score(y_val, y_val_pred, pos_label=1, zero_division=0)\n",
        "    recall = recall_score(y_val, y_val_pred, pos_label=1, zero_division=0)\n",
        "    if precision == 0 and recall == 0:\n",
        "        f_beta = 0\n",
        "    else:\n",
        "        f_beta = (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall)\n",
        "\n",
        "    results_sigmoid.append([C, error_rate, precision, recall, f_beta])\n",
        "\n",
        "results_sigmoid_df = pd.DataFrame(results_sigmoid, columns=[\"C\", \"Error Rate (%)\", \"Precision\", \"Recall\", f\"F_{beta} Measure\"])\n",
        "print(\"Sigmoid Kernel Results\")\n",
        "print(results_sigmoid_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrrkxzKSVeQi",
        "outputId": "72582894-8507-4e40-cea7-acb31074c7b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sigmoid Kernel Results\n",
            "        C  Error Rate (%)  Precision  Recall  F_1 Measure\n",
            "0     0.1       43.137255        0.0     0.0            0\n",
            "1     1.0       43.137255        0.0     0.0            0\n",
            "2    10.0       76.470588        0.0     0.0            0\n",
            "3   100.0       82.352941        0.0     0.0            0\n",
            "4  1000.0       84.313725        0.0     0.0            0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Collecting All Results into a Table:"
      ],
      "metadata": {
        "id": "M26k6uZbVgk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_combined = pd.concat([\n",
        "    results_poly_df.assign(Kernel=\"Polynomial\"),\n",
        "    results_rbf_df.assign(Kernel=\"RBF\"),\n",
        "    results_sigmoid_df.assign(Kernel=\"Sigmoid\")\n",
        "])\n",
        "\n",
        "print(\"Combined Results\")\n",
        "print(results_combined)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQUuGr-2Vj4n",
        "outputId": "6eb4fcb1-d29b-4cdb-9e67-01c2aab3a4ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Results\n",
            "        C  Error Rate (%)  Precision    Recall  F_1 Measure      Kernel\n",
            "0     0.1        1.960784   1.000000  0.954545     0.976744  Polynomial\n",
            "1     1.0        1.960784   1.000000  0.954545     0.976744  Polynomial\n",
            "2    10.0        1.960784   1.000000  0.954545     0.976744  Polynomial\n",
            "3   100.0        3.921569   0.954545  0.954545     0.954545  Polynomial\n",
            "4  1000.0        7.843137   0.875000  0.954545     0.913043  Polynomial\n",
            "0     0.1        3.921569   1.000000  0.909091     0.952381         RBF\n",
            "1     1.0        1.960784   1.000000  0.954545     0.976744         RBF\n",
            "2    10.0        1.960784   1.000000  0.954545     0.976744         RBF\n",
            "3   100.0        3.921569   0.954545  0.954545     0.954545         RBF\n",
            "4  1000.0        3.921569   0.954545  0.954545     0.954545         RBF\n",
            "0     0.1       43.137255   0.000000  0.000000     0.000000     Sigmoid\n",
            "1     1.0       43.137255   0.000000  0.000000     0.000000     Sigmoid\n",
            "2    10.0       76.470588   0.000000  0.000000     0.000000     Sigmoid\n",
            "3   100.0       82.352941   0.000000  0.000000     0.000000     Sigmoid\n",
            "4  1000.0       84.313725   0.000000  0.000000     0.000000     Sigmoid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Choosing the best value $C = C^*_\\alpha$.\n",
        "\n",
        "The optimal value of $ C $ is **1.0**, with the best performance achieved using any of the **Polynomial** or **RBF** kernels. Both of them provide a low error rate (1.96%), high precision (1.0), recall (0.954545), and F1 measure (0.976744), what makes them the most effective configurations.\n",
        "\n",
        "The Sigmoid kernel is not suitable due to its high error rates and poor metrics across all \\( C \\) values.\n",
        "\n"
      ],
      "metadata": {
        "id": "0LDY81FoWVGB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12"
      ],
      "metadata": {
        "id": "QXpAYhwrXmyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "# Define variables\n",
        "C_values = [1]  # C* for all models (determined earlier)\n",
        "beta = 1  # For F_beta calculation\n",
        "kernels = ['linear', 'poly', 'rbf', 'sigmoid']  # Models I-IV\n",
        "degree = 3  # For Polynomial kernel\n",
        "gamma = 1  # Fixed for RBF and Sigmoid\n",
        "results = []\n",
        "\n",
        "# Iterate over kernels\n",
        "for kernel in kernels:\n",
        "    if kernel == 'linear':\n",
        "        # Model I (Linear Kernel)\n",
        "        model = SVC(C=C_values[0], kernel='linear')\n",
        "    elif kernel == 'poly':\n",
        "        # Model II (Polynomial Kernel)\n",
        "        model = SVC(C=C_values[0], kernel='poly', degree=degree, coef0=1, gamma=gamma)\n",
        "    elif kernel == 'rbf':\n",
        "        # Model III (RBF Kernel)\n",
        "        model = SVC(C=C_values[0], kernel='rbf', gamma=gamma)\n",
        "    elif kernel == 'sigmoid':\n",
        "        # Model IV (Sigmoid Kernel)\n",
        "        model = SVC(C=C_values[0], kernel='sigmoid', coef0=1, gamma=gamma)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported kernel: {kernel}\")\n",
        "\n",
        "    # Train the model on the full training set\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # (a) Calculate Error Rate\n",
        "    error_rate = 100 * (1 - accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "    # (b) Calculate Precision and Recall\n",
        "    precision = precision_score(y_test, y_test_pred, pos_label=1, zero_division=0)\n",
        "    recall = recall_score(y_test, y_test_pred, pos_label=1, zero_division=0)\n",
        "\n",
        "    # (c) Calculate F_beta Measure\n",
        "    if precision == 0 and recall == 0:\n",
        "        f_beta = 0\n",
        "    else:\n",
        "        f_beta = (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall)\n",
        "\n",
        "    # Append results\n",
        "    results.append([kernel, error_rate, precision, recall, f_beta])\n",
        "\n",
        "# Summarize results in a DataFrame\n",
        "import pandas as pd\n",
        "results_df = pd.DataFrame(results, columns=[\"Kernel\", \"Error Rate (%)\", \"Precision\", \"Recall\", f\"F_{beta} Measure\"])\n",
        "print(results_df)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7_FiiLcXn2N",
        "outputId": "1fcf4809-9c87-4569-ae38-0d71478d263c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Kernel  Error Rate (%)  Precision    Recall  F_1 Measure\n",
            "0   linear        9.803922       0.84  0.954545     0.893617\n",
            "1     poly        5.882353       0.88  1.000000     0.936170\n",
            "2      rbf        5.882353       0.88  1.000000     0.936170\n",
            "3  sigmoid       43.137255       0.00  0.000000     0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "As we might observe form the Table Results, the Polynomial and RBF kernels achieve equally the lowest error rate (5.88%) and the highest F1 measure (0.936), making them the best models.\n",
        "From the other hand,\n",
        " The Linear kernel performs reasonably well, but the little worse, than Polynomial and RBF kernels.\n",
        "\n",
        " The Sigmoid kernel performs poorly with a high error rate (43.14%) and no correctly classified positives, making it totally unsuitable.\n",
        "\n",
        " So, the conclusion is that we choose Polynomial kernel, if we care about better interpretability of results. And if we want to have a better generalization for a non-linear scenarios, I would choose RBF kernel.\n",
        "\n"
      ],
      "metadata": {
        "id": "Q1iMFy02cpcJ"
      }
    }
  ]
}
